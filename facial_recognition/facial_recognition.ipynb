{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch \n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"/Users/menghang/Desktop/ml-dev/ml-replicate/vector-db/facial_recognition/lfw_funneled/Alejandro_Toledo\"\n",
    "p2 = \"/Users/menghang/Desktop/ml-dev/ml-replicate/vector-db/facial_recognition/lfw_funneled/Allyson_Felix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_embed ={\n",
    "    \"genre\": \"men\", \n",
    "    \"data\": []\n",
    "}\n",
    "p2_embed ={\n",
    "    \"genre\": \"women\", \n",
    "    \"data\": []\n",
    "}\n",
    "\n",
    "resnet = resnet50( weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "model = nn.Sequential(*list(resnet.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in sorted(glob.glob(p1 + \"/*\"), key=os.path.getctime): \n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224,224)).transpose((2,0,1))\n",
    "    features = model(torch.Tensor([img]))\n",
    "    flattened = features.view(features.size(0), -1)[0].tolist()\n",
    "    p1_embed['data'].append(flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in sorted(glob.glob(p2 + \"/*\"), key=os.path.getctime): \n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224,224)).transpose((2,0,1))\n",
    "    features = model(torch.Tensor([img]))\n",
    "    flattened = features.view(features.size(0), -1)[0].tolist()\n",
    "    p2_embed['data'].append(flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(\"facial-recognition\",metadata={\"hnsw:space\": \"cosine\"},)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id-f0\n",
      "Add of existing embedding ID: id-f1\n",
      "Add of existing embedding ID: id-f2\n",
      "Add of existing embedding ID: id-f3\n",
      "Add of existing embedding ID: id-f4\n",
      "Insert of existing embedding ID: id-f0\n",
      "Insert of existing embedding ID: id-f1\n",
      "Insert of existing embedding ID: id-f2\n",
      "Insert of existing embedding ID: id-f3\n",
      "Insert of existing embedding ID: id-f4\n"
     ]
    }
   ],
   "source": [
    "collection.add(embeddings=p2_embed[\"data\"], metadatas=[{\"gender\": \"female\"} for _ in range(len(p2_embed[\"data\"]))] , ids=[f\"id-f{x}\" for x in range(len(p2_embed[\"data\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id-m0\n",
      "Add of existing embedding ID: id-m1\n",
      "Add of existing embedding ID: id-m2\n",
      "Add of existing embedding ID: id-m3\n",
      "Add of existing embedding ID: id-m4\n",
      "Add of existing embedding ID: id-m5\n",
      "Add of existing embedding ID: id-m6\n",
      "Add of existing embedding ID: id-m7\n",
      "Add of existing embedding ID: id-m8\n",
      "Add of existing embedding ID: id-m9\n",
      "Add of existing embedding ID: id-m10\n",
      "Add of existing embedding ID: id-m11\n",
      "Add of existing embedding ID: id-m12\n",
      "Add of existing embedding ID: id-m13\n",
      "Add of existing embedding ID: id-m14\n",
      "Add of existing embedding ID: id-m15\n",
      "Add of existing embedding ID: id-m16\n",
      "Add of existing embedding ID: id-m17\n",
      "Add of existing embedding ID: id-m18\n",
      "Add of existing embedding ID: id-m19\n",
      "Add of existing embedding ID: id-m20\n",
      "Add of existing embedding ID: id-m21\n",
      "Add of existing embedding ID: id-m22\n",
      "Add of existing embedding ID: id-m23\n",
      "Add of existing embedding ID: id-m24\n",
      "Add of existing embedding ID: id-m25\n",
      "Add of existing embedding ID: id-m26\n",
      "Add of existing embedding ID: id-m27\n",
      "Add of existing embedding ID: id-m28\n",
      "Add of existing embedding ID: id-m29\n",
      "Add of existing embedding ID: id-m30\n",
      "Add of existing embedding ID: id-m31\n",
      "Add of existing embedding ID: id-m32\n",
      "Add of existing embedding ID: id-m33\n",
      "Add of existing embedding ID: id-m34\n",
      "Add of existing embedding ID: id-m35\n",
      "Add of existing embedding ID: id-m36\n",
      "Add of existing embedding ID: id-m37\n",
      "Add of existing embedding ID: id-m38\n",
      "Insert of existing embedding ID: id-m0\n",
      "Insert of existing embedding ID: id-m1\n",
      "Insert of existing embedding ID: id-m2\n",
      "Insert of existing embedding ID: id-m3\n",
      "Insert of existing embedding ID: id-m4\n",
      "Insert of existing embedding ID: id-m5\n",
      "Insert of existing embedding ID: id-m6\n",
      "Insert of existing embedding ID: id-m7\n",
      "Insert of existing embedding ID: id-m8\n",
      "Insert of existing embedding ID: id-m9\n",
      "Insert of existing embedding ID: id-m10\n",
      "Insert of existing embedding ID: id-m11\n",
      "Insert of existing embedding ID: id-m12\n",
      "Insert of existing embedding ID: id-m13\n",
      "Insert of existing embedding ID: id-m14\n",
      "Insert of existing embedding ID: id-m15\n",
      "Insert of existing embedding ID: id-m16\n",
      "Insert of existing embedding ID: id-m17\n",
      "Insert of existing embedding ID: id-m18\n",
      "Insert of existing embedding ID: id-m19\n",
      "Insert of existing embedding ID: id-m20\n",
      "Insert of existing embedding ID: id-m21\n",
      "Insert of existing embedding ID: id-m22\n",
      "Insert of existing embedding ID: id-m23\n",
      "Insert of existing embedding ID: id-m24\n",
      "Insert of existing embedding ID: id-m25\n",
      "Insert of existing embedding ID: id-m26\n",
      "Insert of existing embedding ID: id-m27\n",
      "Insert of existing embedding ID: id-m28\n",
      "Insert of existing embedding ID: id-m29\n",
      "Insert of existing embedding ID: id-m30\n",
      "Insert of existing embedding ID: id-m31\n",
      "Insert of existing embedding ID: id-m32\n",
      "Insert of existing embedding ID: id-m33\n",
      "Insert of existing embedding ID: id-m34\n",
      "Insert of existing embedding ID: id-m35\n",
      "Insert of existing embedding ID: id-m36\n",
      "Insert of existing embedding ID: id-m37\n",
      "Insert of existing embedding ID: id-m38\n"
     ]
    }
   ],
   "source": [
    "collection.add(embeddings=p1_embed[\"data\"], metadatas=[{\"gender\": \"male\"} for _ in range(len(p1_embed[\"data\"]))] , ids=[f\"id-m{x}\" for x in range(len(p1_embed[\"data\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/Users/menghang/Desktop/ml-dev/ml-replicate/vector-db/Alejandro_Toledo_0037.jpg\")\n",
    "img = cv2.resize(img, (224,224)).transpose((2,0,1))\n",
    "features = model(torch.Tensor([img]))\n",
    "flattened = features.view(features.size(0), -1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(query_embeddings=flattened, n_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id-m17',\n",
       "   'id-m29',\n",
       "   'id-m11',\n",
       "   'id-m16',\n",
       "   'id-m36',\n",
       "   'id-m38',\n",
       "   'id-m20',\n",
       "   'id-m28',\n",
       "   'id-m9',\n",
       "   'id-f3']],\n",
       " 'distances': [[13.239620208740234,\n",
       "   14.626680374145508,\n",
       "   15.118236541748047,\n",
       "   15.335177421569824,\n",
       "   15.775787353515625,\n",
       "   15.857386589050293,\n",
       "   15.976330757141113,\n",
       "   17.17392921447754,\n",
       "   17.39162254333496,\n",
       "   17.69011878967285]],\n",
       " 'metadatas': [[{'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'male'},\n",
       "   {'gender': 'female'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
